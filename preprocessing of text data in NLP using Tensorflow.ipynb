{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALfgOTvIuACD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer #its for tokenizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElTMMvX9uJOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence=['my name is puneet',\n",
        "          'this is dog ',\n",
        "          'this is cat',\n",
        "           'Do you think my dog is amazing?']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhhAceM_umfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f546e57-3e5a-43df-deca-109706394d46"
      },
      "source": [
        "token=Tokenizer(num_words=100)\n",
        "# create object and intilize tokenize\n",
        "# num_words=100 it mean it take 100 most frequenctly words and count that words(for more information go and read from interent)\n",
        "token.fit_on_texts(sentence) # fit sentence into token\n",
        "print(type(token))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'keras_preprocessing.text.Tokenizer'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JT0q0sKu9b5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72e03f57-9c00-488a-f58c-ef7d61b6eb82"
      },
      "source": [
        "word_index=token.word_index # it convert all words in form of dictionary and assign specific no to each word.\n",
        "#repeatation is not allow of words in dictionary\n",
        "print(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'is': 1, 'my': 2, 'this': 3, 'dog': 4, 'name': 5, 'puneet': 6, 'cat': 7, 'do': 8, 'you': 9, 'think': 10, 'amazing': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvNrOACYvLDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now come in texts_to_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ysCOUGjxPsb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSYpeg9txRlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjMhojslxM10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = token.texts_to_sequences(sentence) # sentences convert into 2d vectors but one problem is in this.all are vector are not is same dimesional\n",
        "# its mean for performing some ML algo all dimesional are must be same.\n",
        "# so overcome this limitation we use padding , its same as padding operations in CNN."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwSRDMnnyBD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "850594cd-5130-4762-c832-fbfe984f3ee8"
      },
      "source": [
        "print(sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 5, 1, 6], [3, 1, 4], [3, 1, 7], [8, 9, 10, 2, 4, 1, 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIEZ6QoQyDLv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f522b780-9ffa-4342-a3ef-e43383677304"
      },
      "source": [
        "padded = pad_sequences(sequences, maxlen=5)\n",
        "# here pad_sequences constructor take two arguments , 1 where padding perform its compalsory argument, 2nd len max how many dimension , by default which sentence is larger padding size will that.\n",
        "print(padded)\n",
        "# now all dimension are same we can fit it into ML algoriithm\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  2  5  1  6]\n",
            " [ 0  0  3  1  4]\n",
            " [ 0  0  3  1  7]\n",
            " [10  2  4  1 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xZ_yVwU0Ab_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "70fa2b1c-06fe-4bbb-830d-b3214629d4f8"
      },
      "source": [
        "padded = pad_sequences(sequences, maxlen=3) # here maxlen is 3 . see vectors\n",
        "print(padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5  1  6]\n",
            " [ 3  1  4]\n",
            " [ 3  1  7]\n",
            " [ 4  1 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpBa9xhZ1E_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "129e883d-3e48-4964-e7c8-d1f16e40699c"
      },
      "source": [
        "padded = pad_sequences(sequences) # here no maxlen so it take  by default. see vectors\n",
        "print(padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  2  5  1  6]\n",
            " [ 0  0  0  0  3  1  4]\n",
            " [ 0  0  0  0  3  1  7]\n",
            " [ 8  9 10  2  4  1 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrw4k8Dm1acv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try with words that the tokenizer wasn't fit to\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-TAlOVX1mP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = [\n",
        "    'i really love my dog!',\n",
        "    'my dog loves kkka my manatee'\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr_76S8X1qNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(test_data)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKo5yqO_1yEA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd2d61aa-8580-4b1c-fa0f-7893756e2d0b"
      },
      "source": [
        "print(word_index) # here love and loves consider is same and ignor ! or more  this kind of  special symbols, so dog! and dog consider same."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'my': 1, 'dog': 2, 'i': 3, 'really': 4, 'love': 5, 'loves': 6, 'kkka': 7, 'manatee': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7CbyPaG2Fq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e9e11347-6d49-467e-a112-9c93c7be6a7b"
      },
      "source": [
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "print(\"\\nTest Sequence = \", test_seq)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Sequence =  [[3, 4, 5, 1, 2], [1, 2, 6, 7, 1, 8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78SUWRfS24Py",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8194267e-f925-4b38-e491-ba00c5a8ef22"
      },
      "source": [
        "padded = pad_sequences(test_seq, maxlen=10) # here maxlen is 10 so vector look like in 10 D\n",
        "print(\"\\nPadded Test Sequence: \")\n",
        "print(padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padded Test Sequence: \n",
            "[[0 0 0 0 0 3 4 5 1 2]\n",
            " [0 0 0 0 1 2 6 7 1 8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArBDMLkL3cXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}